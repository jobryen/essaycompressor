{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pywt\n",
    "import struct\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Read file and convert to greyscale\n",
    "\n",
    "- 8 bit vs 16 bit?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path = 'TestPhotos/GREYtest.png'\n",
    "image = Image.open(image_path).convert('L')\n",
    "image_array = np.array(image, dtype=np.uint8)\n",
    "\n",
    "height, width = image_array.shape\n",
    "image_size = os.path.getsize(image_path)\n",
    "print(f\"Loaded image: {width} x {height} pixels, grayscale,\", image_size, \"bytes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Apply a multilevel DWT with haar wavelet and L levels, definitly not the most optimal wavelet, will use a better one down the line, also need to find the best value for L to use\n",
    "\n",
    "The `coeffs` list structure:\n",
    "\n",
    "coeffs[0] is the approximation coefficients at level L (cA_L)\n",
    "\n",
    "coeffs[1:] are detail coefficients tuples for levels L, L-1, ..., 1:\n",
    "\n",
    "e.g., coeffs[1] = (cH_L, cV_L, cD_L), coeffs[2] = (cH_{L-1}, cV_{L-1}, cD_{L-1}), ..., coeffs[L] = (cH_1, cV_1, cD_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_name = 'haar'\n",
    "L = 3 \n",
    "\n",
    "coeffs = pywt.wavedec2(image, wavelet_name, level=L)\n",
    "\n",
    "print(f\"Decomposed into {len(coeffs)-1} levels of detail coefficients plus approximation.\")\n",
    "print(\"Approximation (cA_L) shape:\", coeffs[0].shape)\n",
    "for level, details in enumerate(coeffs[1:], start=1):\n",
    "    cH, cV, cD = details\n",
    "    print(f\"Level {L+1-level} detail shapes (cH, cV, cD): {cH.shape}, {cV.shape}, {cD.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Use thresholding to zero out small coefficients (lossy compression) as they have little effect on final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fraction = 0.003\n",
    "\n",
    "# find biggest coeff\n",
    "all_coeffs = [coeffs[0]]  \n",
    "for detail in coeffs[1:]:\n",
    "    all_coeffs.extend(detail) \n",
    "max_coeff = max(np.max(np.abs(arr)) for arr in all_coeffs)\n",
    "threshold_value = threshold_fraction * max_coeff\n",
    "\n",
    "coeffs_thresh = [None] * len(coeffs)\n",
    "cA = coeffs[0].copy()\n",
    "cA[np.abs(cA) < threshold_value] = 0\n",
    "coeffs_thresh[0] = cA\n",
    "\n",
    "for i, detail in enumerate(coeffs[1:], start=1):\n",
    "    cH, cV, cD = detail\n",
    "    cH_th = cH.copy(); cH_th[np.abs(cH_th) < threshold_value] = 0\n",
    "    cV_th = cV.copy(); cV_th[np.abs(cV_th) < threshold_value] = 0\n",
    "    cD_th = cD.copy(); cD_th[np.abs(cD_th) < threshold_value] = 0\n",
    "    coeffs_thresh[i] = (cH_th, cV_th, cD_th)\n",
    "\n",
    "total_coeffs = sum(arr.size for arr in all_coeffs)\n",
    "nonzero_coeffs = sum(np.count_nonzero(arr) for arr in [coeffs_thresh[0]] + [d for detail in coeffs_thresh[1:] for d in detail])\n",
    "print(f\"Total coefficients: {total_coeffs}, Non-zeros after threshold: {nonzero_coeffs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Quantise coefficients uniformly, from floating point numbers to intagers using 8-bit quantisation (256 levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_levels = 256 \n",
    "\n",
    "# min and max to scale\n",
    "min_val = min(np.min(arr) for arr in all_coeffs)\n",
    "max_val = max(np.max(arr) for arr in all_coeffs)\n",
    "if max_val == min_val:\n",
    "    step_size = 1.0\n",
    "else:\n",
    "    step_size = (max_val - min_val) / (quant_levels - 1)\n",
    "\n",
    "# uniform quantise\n",
    "quantized_coeffs = [None] * len(coeffs_thresh)\n",
    "\n",
    "cA_th = coeffs_thresh[0]\n",
    "qA = np.rint((cA_th - min_val) / step_size).astype(np.int16)\n",
    "qA[cA_th == 0] = 0  # needa to check that i havent actaully set the threshold coefficients to zero twice lol\n",
    "qA = np.clip(qA, 0, quant_levels-1)\n",
    "quantized_coeffs[0] = qA\n",
    "\n",
    "\n",
    "for i, detail in enumerate(coeffs_thresh[1:], start=1):\n",
    "    cH_th, cV_th, cD_th = detail\n",
    "    qH = np.rint((cH_th - min_val) / step_size).astype(np.int16)\n",
    "    qV = np.rint((cV_th - min_val) / step_size).astype(np.int16)\n",
    "    qD = np.rint((cD_th - min_val) / step_size).astype(np.int16)\n",
    "    # second time being here haha ------------------------------------------\n",
    "    qH[cH_th == 0] = 0\n",
    "    qV[cV_th == 0] = 0\n",
    "    qD[cD_th == 0] = 0\n",
    "    qH = np.clip(qH, 0, quant_levels-1)\n",
    "    qV = np.clip(qV, 0, quant_levels-1)\n",
    "    qD = np.clip(qD, 0, quant_levels-1)\n",
    "    quantized_coeffs[i] = (qH, qV, qD)\n",
    "\n",
    "print(\"Quantization step size:\", step_size)\n",
    "print(\"Example quantized coeff range:\", np.min(qA), \"to\", np.max(qA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Serialise coefficients and metadata to store in a file, also store the following metadata\n",
    "\n",
    "image dimensions\n",
    "wavelet type\n",
    "decomposition levels\n",
    "thresholding and quantisation information (thresholding doesnt matter to decode)\n",
    "length of encoded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_coeffs = []\n",
    "# approximation\n",
    "flat_coeffs.extend(quantized_coeffs[0].ravel().tolist())\n",
    "# Append detail coefficients for each level\n",
    "for detail in quantized_coeffs[1:]:\n",
    "    qH, qV, qD = detail\n",
    "    flat_coeffs.extend(qH.ravel().tolist())\n",
    "    flat_coeffs.extend(qV.ravel().tolist())\n",
    "    flat_coeffs.extend(qD.ravel().tolist())\n",
    "\n",
    "total_values = len(flat_coeffs)\n",
    "print(\"Total values to encode (should equal image size):\", total_values)\n",
    "\n",
    "# can we not entirely disregard the zeros coefficients instead of making them smaller in the entropy coding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "apply entropy coding to losslessly reduce length of serialised string (from MA3K0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(values, sentinel=0xFFFF):\n",
    "    \"\"\"Basic run-length encoding for a list of integers. \n",
    "    Uses `sentinel` followed by count to encode runs of zeros (length >=3).\"\"\"\n",
    "    encoded = []\n",
    "    i = 0\n",
    "    n = len(values)\n",
    "    while i < n:\n",
    "        if values[i] != 0:\n",
    "            # Non-zero value: encode it directly\n",
    "            encoded.append(values[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            # Zero run detected\n",
    "            j = i\n",
    "            while j < n and values[j] == 0:\n",
    "                j += 1\n",
    "            run_len = j - i  # length of this zero-run\n",
    "            if run_len < 3:\n",
    "                # For short runs, output literal zeros (no compression gain for 1 or 2 zeros)\n",
    "                encoded.extend([0] * run_len)\n",
    "            else:\n",
    "                # Use sentinel to encode a long run of zeros\n",
    "                full_runs = run_len // 0xFFFF\n",
    "                remainder = run_len % 0xFFFF\n",
    "                # If run is very long, split into multiple sentinel segments\n",
    "                for _ in range(full_runs):\n",
    "                    encoded.append(sentinel)\n",
    "                    encoded.append(0xFFFF)  # maximum count for a run in one segment\n",
    "                if remainder > 0:\n",
    "                    encoded.append(sentinel)\n",
    "                    encoded.append(remainder)\n",
    "            i = j\n",
    "    return encoded\n",
    "\n",
    "# RLE to the flat coefficient list\n",
    "encoded_values = rle_encode(flat_coeffs)\n",
    "print(f\"RLE encoded length: {len(encoded_values)} (16-bit words)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now produce the .Job file, with the following data structure\n",
    "\n",
    "width\n",
    "height\n",
    "dwt levels\n",
    "wavelet name\n",
    "threshold data\n",
    "quantisation data\n",
    "total coefficient count (should be width * height)\n",
    "encoded data length\n",
    "encoded coefficnent data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_available(path: str, sep: str = \"_\") -> str:\n",
    "    folder, filename = os.path.split(path)\n",
    "    stem, ext = os.path.splitext(filename)\n",
    "\n",
    "    candidate = path\n",
    "    i = 1\n",
    "    while os.path.exists(candidate):\n",
    "        candidate = os.path.join(folder, f\"{stem}{sep}{i}{ext}\")\n",
    "        i += 1\n",
    "    return candidate\n",
    "\n",
    "out_path = os.path.splitext(image_path)[0] + 'encoded.job'\n",
    "output_filename = name_available(out_path)\n",
    "\n",
    "with open(output_filename, \"wb\") as f:\n",
    "    # width height and level\n",
    "    f.write(struct.pack('<H', image_array.shape[1])) \n",
    "    f.write(struct.pack('<H', image_array.shape[0])) \n",
    "    f.write(struct.pack('<B', L))\n",
    "    # Wavelet name\n",
    "    wavelet_bytes = wavelet_name.encode('ascii')\n",
    "    f.write(struct.pack('<B', len(wavelet_bytes)))\n",
    "    f.write(wavelet_bytes)\n",
    "    # Threshold fraction and quantization parameters\n",
    "    f.write(struct.pack('<f', threshold_fraction))\n",
    "    f.write(struct.pack('<f', float(min_val)))\n",
    "    f.write(struct.pack('<f', float(step_size)))\n",
    "    # Counts\n",
    "    total_count = total_values\n",
    "    encoded_count = len(encoded_values)\n",
    "    f.write(struct.pack('<I', total_count))\n",
    "    f.write(struct.pack('<I', encoded_count))\n",
    "    # Encode list as 16-bit words\n",
    "    data_array = np.array(encoded_values, dtype=np.uint16)\n",
    "    f.write(data_array.tobytes())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
