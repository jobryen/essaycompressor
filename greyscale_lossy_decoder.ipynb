{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "to decode our .job format awe need to do the following in order\n",
    "\n",
    "- parses metadata (dims, levels, wavelet, quant params)\n",
    "- RLE-decodes coefficients\n",
    "- dequantises (`0` treated as explicit zero)\n",
    "- rebuilds the `wavedec2` coefficient tree using shapes inferred from metadata\n",
    "- reconstructs via inverse DWT\n",
    "- displays and saves `***_uncompressed.png`\n",
    "- computes PSNR/SSIM if the original image is provided\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "job_path = \"TestPhotos/GREYtest_compressed.job\"\n",
    "\n",
    "#original file to see compression artifacts\n",
    "original_image_path = \"TestPhotos/GREYtest.png\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Lets now extract the metadata from .job file to determine how to decode\n",
    "structure is:\n",
    "      uint16 width\n",
    "      uint16 height\n",
    "      uint8  L (levels)\n",
    "      uint8  wavelet_name_length\n",
    "      bytes  wavelet_name (ASCII)\n",
    "      float32 threshold_fraction\n",
    "      float32 min_val\n",
    "      float32 step_size\n",
    "      uint32 total_count          # expected = width * height\n",
    "      uint32 encoded_count        # number of uint16 words following\n",
    "      uint16[encoded_count] encoded_values (RLE stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_job_header_and_payload(path: str):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    off = 0\n",
    "    width  = struct.unpack_from(\"<H\", data, off)[0]; off += 2\n",
    "    height = struct.unpack_from(\"<H\", data, off)[0]; off += 2\n",
    "    L      = struct.unpack_from(\"<B\", data, off)[0]; off += 1\n",
    "\n",
    "    name_len = struct.unpack_from(\"<B\", data, off)[0]; off += 1\n",
    "    wavelet_name = data[off:off+name_len].decode(\"ascii\"); off += name_len\n",
    "\n",
    "    threshold_fraction = struct.unpack_from(\"<f\", data, off)[0]; off += 4\n",
    "    min_val = struct.unpack_from(\"<f\", data, off)[0]; off += 4\n",
    "    step_size = struct.unpack_from(\"<f\", data, off)[0]; off += 4\n",
    "\n",
    "    total_count = struct.unpack_from(\"<I\", data, off)[0]; off += 4\n",
    "    encoded_count = struct.unpack_from(\"<I\", data, off)[0]; off += 4\n",
    "\n",
    "    encoded = np.frombuffer(data, dtype=\"<u2\", offset=off, count=encoded_count).copy()\n",
    "\n",
    "    header = dict(\n",
    "        width=width,\n",
    "        height=height,\n",
    "        L=L,\n",
    "        wavelet_name=wavelet_name,\n",
    "        threshold_fraction=threshold_fraction,\n",
    "        min_val=min_val,\n",
    "        step_size=step_size,\n",
    "        total_count=total_count,\n",
    "        encoded_count=encoded_count,\n",
    "    )\n",
    "    return header, encoded\n",
    "\n",
    "header, encoded_values = read_job_header_and_payload(job_path)\n",
    "\n",
    "print(\"Metadata:\")\n",
    "for k,v in header.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"Encoded stream uint16 length:\", encoded_values.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We now need to reverse the entropy coding eg. re-adding the zeros that've been compresed\n",
    "\n",
    "then compare with the origial provided length to check all is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(encoded: np.ndarray, sentinel: int = 0xFFFF) -> np.ndarray:\n",
    "    out = []\n",
    "    i = 0\n",
    "    n = int(encoded.size)\n",
    "    while i < n:\n",
    "        val = int(encoded[i]); i += 1\n",
    "        if val != sentinel:\n",
    "            out.append(val)\n",
    "        else:\n",
    "            if i >= n:\n",
    "                raise ValueError(\"Malformed RLE stream: sentinel at end with no count.\")\n",
    "            run_len = int(encoded[i]); i += 1\n",
    "            out.extend([0] * run_len)\n",
    "    return np.array(out, dtype=np.uint16)\n",
    "\n",
    "flat_q = rle_decode(encoded_values, sentinel=0xFFFF)\n",
    "print(\"Decoded coefficient codes length:\", flat_q.size, \"(expected\", header[\"total_count\"], \")\")\n",
    "assert flat_q.size == header[\"total_count\"], \"Decoded length does not match header total_count.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "rebuild coefficient tree, dequantise\n",
    "\n",
    "    Wavedec2 coefficient structure \n",
    "      [cA_L, (cH_L,cV_L,cD_L), ..., (cH_1,cV_1,cD_1)]\n",
    "\n",
    "    Dequantisation rule (matches encoder):\n",
    "      - code == 0  -> coefficient = 0.0   (explicit zero from thresholding)\n",
    "      - code > 0   -> coefficient â‰ˆ code * step_size + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_coeff_shapes(height: int, width: int, wavelet_name: str, L: int, mode: str = \"symmetric\"):\n",
    "    '''\n",
    "    Use a dummy zero image to infer the wavedec2 coefficient array shapes for (H,W,wavelet,L).\n",
    "    Keeps the decoder flexible for wavelet choice and level count.\n",
    "    '''\n",
    "    dummy = np.zeros((height, width), dtype=np.float32)\n",
    "    coeffs = pywt.wavedec2(dummy, wavelet_name, level=L, mode=mode)\n",
    "    shapes = [coeffs[0].shape] + [tuple(arr.shape for arr in detail) for detail in coeffs[1:]]\n",
    "    return shapes\n",
    "\n",
    "def build_coeff_tree_from_flat(flat_q: np.ndarray, header: dict, mode: str = \"symmetric\"):\n",
    "\n",
    "    #Reconstructs the wavedec2 coeff list:\n",
    "\n",
    "    H = int(header[\"height\"])\n",
    "    W = int(header[\"width\"])\n",
    "    L = int(header[\"L\"])\n",
    "    wavelet = header[\"wavelet_name\"]\n",
    "    min_val = float(header[\"min_val\"])\n",
    "    step = float(header[\"step_size\"])\n",
    "\n",
    "    shapes = infer_coeff_shapes(H, W, wavelet, L, mode=mode)\n",
    "\n",
    "    def dequantise(codes_1d: np.ndarray) -> np.ndarray:\n",
    "        codes_f = codes_1d.astype(np.float32)\n",
    "        out = codes_f * step + min_val\n",
    "        out[codes_f == 0] = 0.0  # preserve explicit zeros\n",
    "        return out\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    # Approximation cA_L\n",
    "    cA_shape = shapes[0]\n",
    "    nA = cA_shape[0] * cA_shape[1]\n",
    "    cA_codes = flat_q[idx:idx+nA]; idx += nA\n",
    "    cA = dequantise(cA_codes).reshape(cA_shape)\n",
    "\n",
    "    coeffs = [cA]\n",
    "\n",
    "    # tuples for each level: L down to 1\n",
    "    for (sH, sV, sD) in shapes[1:]:\n",
    "        nH = sH[0] * sH[1]\n",
    "        nV = sV[0] * sV[1]\n",
    "        nD = sD[0] * sD[1]\n",
    "\n",
    "        cH = dequantise(flat_q[idx:idx+nH]).reshape(sH); idx += nH\n",
    "        cV = dequantise(flat_q[idx:idx+nV]).reshape(sV); idx += nV\n",
    "        cD = dequantise(flat_q[idx:idx+nD]).reshape(sD); idx += nD\n",
    "\n",
    "        coeffs.append((cH, cV, cD))\n",
    "\n",
    "    if idx != flat_q.size:\n",
    "        raise ValueError(f\"Did not consume the whole coefficient stream: used {idx}, total {flat_q.size}\")\n",
    "\n",
    "    return coeffs\n",
    "\n",
    "coeffs_rec = build_coeff_tree_from_flat(flat_q, header, mode=\"symmetric\")\n",
    "print(\"Rebuilt coeff tree length:\", len(coeffs_rec), \"(should be L+1 =\", header[\"L\"]+1, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "we now run an inverse discrete wavelet transform (IDWT), and confirm we have the correct image size, then convert to uint8!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = pywt.waverec2(coeffs_rec, header[\"wavelet_name\"], mode=\"symmetric\")\n",
    "\n",
    "# ensure correct dimensions (waverec2 can be wrong)\n",
    "rec = rec[:header[\"height\"], :header[\"width\"]]\n",
    "\n",
    "# Convert to uint8 for display/save\n",
    "rec_u8 = np.clip(np.rint(rec), 0, 255).astype(np.uint8)\n",
    "\n",
    "print(\"Reconstructed image shape:\", rec_u8.shape, \"dtype:\", rec_u8.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "we now check and save the image, if there already exists a file with our name, add a suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(rec_u8, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Decoded image\")\n",
    "plt.show()\n",
    "\n",
    "def name_available(path: str, sep: str = \"_\") -> str:\n",
    "    folder, filename = os.path.split(path)\n",
    "    stem, ext = os.path.splitext(filename)\n",
    "\n",
    "    candidate = path\n",
    "    i = 1\n",
    "    while os.path.exists(candidate):\n",
    "        candidate = os.path.join(folder, f\"{stem}{sep}{i}{ext}\")\n",
    "        i += 1\n",
    "    return candidate\n",
    "\n",
    "out_path = root + \"_decoded.png\"\n",
    "available_out_path = name_available(out_path)\n",
    "\n",
    "root, _ = os.path.splitext(job_path.rsplit(\"_\", 1)[0])\n",
    "\n",
    "Image.fromarray(rec_u8, mode=\"L\").save(available_out_path)\n",
    "#Image.fromarray(rec_u8, mode=\"L\").save(available_out_path, compress_level = 0) ideally want to do this so we only have our compression isntead of added lossless compression from png\n",
    "print(\"Saved:\", available_out_path)\n",
    "\n",
    "#find compression ratio\n",
    "input_size = os.path.getsize(original_image_path)\n",
    "output_size = os.path.getsize(available_out_path)\n",
    "\n",
    "print('compression ratio ',input_size / output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "we now calculate the errors created due to the lossy compression, we use PSNR and SSIM to see how the structure is changed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if original_image_path is None:\n",
    "    print(\"No original_image_path provided; skipping PSNR/SSIM.\")\n",
    "else:\n",
    "    orig_u8 = np.array(Image.open(original_image_path).convert(\"L\"), dtype=np.uint8)\n",
    "\n",
    "    # Match shapes preemtivly\n",
    "    H = min(orig_u8.shape[0], rec_u8.shape[0])\n",
    "    W = min(orig_u8.shape[1], rec_u8.shape[1])\n",
    "    orig_u8_c = orig_u8[:H, :W]\n",
    "    rec_u8_c = rec_u8[:H, :W]\n",
    "\n",
    "    print(f\"PSNR: {psnr(orig_u8_c, rec_u8_c, data_range=255):.3f} dB\")\n",
    "    print(f\"SSIM: {ssim(orig_u8_c, rec_u8_c, data_range=255):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "ideally we would a PSNR of above 30dB and a SSIM above 0.95 (higher is better for both). This could be achieved by using different wavelets, different quanatisation / "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
